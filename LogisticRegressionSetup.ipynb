{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 34.62365962  78.02469282]\n",
      " [ 30.28671077  43.89499752]\n",
      " [ 35.84740877  72.90219803]\n",
      " [ 60.18259939  86.3085521 ]\n",
      " [ 79.03273605  75.34437644]\n",
      " [ 45.08327748  56.31637178]\n",
      " [ 61.10666454  96.51142588]\n",
      " [ 75.02474557  46.55401354]\n",
      " [ 76.0987867   87.42056972]\n",
      " [ 84.43281996  43.53339331]\n",
      " [ 95.86155507  38.22527806]\n",
      " [ 75.01365839  30.60326323]\n",
      " [ 82.30705337  76.4819633 ]\n",
      " [ 69.36458876  97.71869196]\n",
      " [ 39.53833914  76.03681085]\n",
      " [ 53.97105215  89.20735014]\n",
      " [ 69.07014406  52.74046973]\n",
      " [ 67.94685548  46.67857411]\n",
      " [ 70.66150955  92.92713789]\n",
      " [ 76.97878373  47.57596365]\n",
      " [ 67.37202755  42.83843832]\n",
      " [ 89.67677575  65.79936593]\n",
      " [ 50.53478829  48.85581153]\n",
      " [ 34.21206098  44.2095286 ]\n",
      " [ 77.92409145  68.97235999]\n",
      " [ 62.27101367  69.95445795]\n",
      " [ 80.19018075  44.82162893]\n",
      " [ 93.1143888   38.80067034]\n",
      " [ 61.83020602  50.25610789]\n",
      " [ 38.7858038   64.99568096]\n",
      " [ 61.37928945  72.80788731]\n",
      " [ 85.40451939  57.05198398]\n",
      " [ 52.10797973  63.12762377]\n",
      " [ 52.04540477  69.43286012]\n",
      " [ 40.23689374  71.16774802]\n",
      " [ 54.63510555  52.21388588]\n",
      " [ 33.91550011  98.86943574]\n",
      " [ 64.17698887  80.90806059]\n",
      " [ 74.78925296  41.57341523]\n",
      " [ 34.18364003  75.23772034]\n",
      " [ 83.90239366  56.30804622]\n",
      " [ 51.54772027  46.85629026]\n",
      " [ 94.44336777  65.56892161]\n",
      " [ 82.36875376  40.61825516]\n",
      " [ 51.04775177  45.82270146]\n",
      " [ 62.22267576  52.06099195]\n",
      " [ 77.19303493  70.4582    ]\n",
      " [ 97.77159928  86.72782233]\n",
      " [ 62.0730638   96.76882412]\n",
      " [ 91.5649745   88.69629255]\n",
      " [ 79.94481794  74.16311935]\n",
      " [ 99.27252693  60.999031  ]\n",
      " [ 90.54671411  43.39060181]\n",
      " [ 34.52451385  60.39634246]\n",
      " [ 50.28649612  49.80453881]\n",
      " [ 49.58667722  59.80895099]\n",
      " [ 97.64563396  68.86157272]\n",
      " [ 32.57720017  95.59854761]\n",
      " [ 74.24869137  69.82457123]\n",
      " [ 71.79646206  78.45356225]\n",
      " [ 75.39561147  85.75993667]\n",
      " [ 35.28611282  47.02051395]\n",
      " [ 56.2538175   39.26147251]\n",
      " [ 30.05882245  49.59297387]\n",
      " [ 44.66826172  66.45008615]\n",
      " [ 66.56089447  41.09209808]\n",
      " [ 40.45755098  97.53518549]\n",
      " [ 49.07256322  51.88321182]\n",
      " [ 80.27957401  92.11606081]\n",
      " [ 66.74671857  60.99139403]\n",
      " [ 32.72283304  43.30717306]\n",
      " [ 64.03932042  78.03168802]\n",
      " [ 72.34649423  96.22759297]\n",
      " [ 60.45788574  73.0949981 ]\n",
      " [ 58.84095622  75.85844831]\n",
      " [ 99.8278578   72.36925193]\n",
      " [ 47.26426911  88.475865  ]\n",
      " [ 50.4581598   75.80985953]\n",
      " [ 60.45555629  42.50840944]\n",
      " [ 82.22666158  42.71987854]\n",
      " [ 88.91389642  69.8037889 ]\n",
      " [ 94.83450672  45.6943068 ]\n",
      " [ 67.31925747  66.58935318]\n",
      " [ 57.23870632  59.51428198]\n",
      " [ 80.366756    90.9601479 ]\n",
      " [ 68.46852179  85.5943071 ]\n",
      " [ 42.07545454  78.844786  ]\n",
      " [ 75.47770201  90.424539  ]\n",
      " [ 78.63542435  96.64742717]\n",
      " [ 52.34800399  60.76950526]\n",
      " [ 94.09433113  77.15910509]\n",
      " [ 90.44855097  87.50879176]\n",
      " [ 55.48216114  35.57070347]\n",
      " [ 74.49269242  84.84513685]\n",
      " [ 89.84580671  45.35828361]\n",
      " [ 83.48916274  48.3802858 ]\n",
      " [ 42.26170081  87.10385094]\n",
      " [ 99.31500881  68.77540947]\n",
      " [ 55.34001756  64.93193801]\n",
      " [ 74.775893    89.5298129 ]]\n",
      "[ 0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  0.  0.  1.  1.  0.  1.  1.  0.\n",
      "  1.  1.  0.  1.  0.  0.  1.  1.  1.  0.  0.  0.  1.  1.  0.  1.  0.  0.\n",
      "  0.  1.  0.  0.  1.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.\n",
      "  0.  0.  1.  0.  1.  1.  1.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.\n",
      "  1.  1.  1.  1.  1.  1.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.  1.  0.\n",
      "  1.  1.  0.  1.  1.  1.  1.  1.  1.  1.]\n",
      "[-1, -1, -1]\n",
      "Cost Function Value:  1.62445532583\n",
      "Cost Function Value:  0.210671668487\n",
      "Cost Function Value:  0.204930185946\n",
      "Cost Function Value:  0.203867195067\n",
      "Cost Function Value:  0.203602729878\n",
      "Cost Function Value:  0.203528948727\n",
      "Cost Function Value:  0.20350721751\n",
      "Cost Function Value:  0.203500635861\n",
      "Cost Function Value:  0.203498612549\n",
      "Cost Function Value:  0.203497985463\n",
      "[ 3.98902015  3.72149087  1.71668508]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import string\n",
    "\n",
    "def square(x):\n",
    "        return x*x\n",
    "    \n",
    "class LogisticRegression:\n",
    "    \n",
    "    def __init__(self, regularized = True):\n",
    "        self.regularized = regularized\n",
    "    def sigmoid(self, x):\n",
    "        return 1/(1 + np.exp(-1 * x))\n",
    "    def logistic_function(self, vec, theta):\n",
    "        return self.sigmoid(np.dot(vec,theta))\n",
    "    \n",
    "    def single_value_cost(self, x_vector, theta, y_value):\n",
    "        x_vector = np.append(x_vector, 1)\n",
    "        \n",
    "        return y_value *  np.log(self.logistic_function(x_vector, theta)) + (1 - y_value) *  np.log( 1 - self.logistic_function(x_vector, theta))\n",
    "    def gradient(self,theta, X, y):  \n",
    "        theta = np.matrix(theta)\n",
    "        X = np.matrix(X)\n",
    "        y = np.matrix(y)\n",
    "        n,m = X.shape # for generality\n",
    "        X0 = np.ones((n,1))\n",
    "        X= np.hstack((X,X0))\n",
    "        y = y.T\n",
    "        parameters = int(theta.ravel().shape[1])\n",
    "        grad = np.zeros(parameters)\n",
    "        \n",
    "        error = self.sigmoid(X * theta.T) - y\n",
    "        \n",
    "        for i in range(parameters):\n",
    "            term = np.multiply(error, X[:,i])\n",
    "            grad[i] = np.sum(term) / len(X)\n",
    "\n",
    "        return grad \n",
    "    def reg_gradient(self, X, y, theta, lamb):\n",
    "        \n",
    "        return self.gradient(theta, X, y) + lamb/(len(y)) * np.append(np.array(theta[:-1]), [0])\n",
    "\n",
    "    def cost_function(self, x, theta, y):\n",
    "        m = len(y)\n",
    "        return (-1/(m)) * sum([self.single_value_cost(x[i], theta, y[i]) for i in range(m)])\n",
    "    \n",
    "    def reg_cost_function(self, x, theta, y, lamb):\n",
    "        print('Theta: ', theta)\n",
    "        print('All But Last: ', theta[:-1])\n",
    "        print('Regularization Term: ', np.dot(theta[:-1]), np.dot(theta[:-1]))\n",
    "        return self.cost_function(x, theta, y) + lamb/(2 *len(y)) * np.dot(theta[:-1], theta[:-1])\n",
    "    \n",
    "    def grad_check(self, x, y, index, theta, lamb):\n",
    "        \n",
    "        func_before = self.reg_cost_function(x, theta, y, lamb)\n",
    "        theta[index] += 0.0000001\n",
    "        func_after = self.reg_cost_function(x, theta, y, lamb)\n",
    "        theta[index] -= 0.0000001\n",
    "        return (func_after- func_before) / 0.0000001\n",
    "    \n",
    "    def update_theta(self, theta, alpha, x, y, lamb):\n",
    "        \n",
    "        gradient = self.reg_gradient(x, y, theta, lamb)\n",
    "        \n",
    "        #check_gradient = [self.grad_check(x, y, index, theta, lamb) for index in range(len(theta))]\n",
    "        \n",
    "        #print(gradient)\n",
    "        \n",
    "        #print('Check Gradient: ', check_gradient)\n",
    "        #print('Gradient: ', gradient)\n",
    "        theta = np.array(theta) - alpha * np.array(gradient)\n",
    "        \n",
    "        return theta\n",
    "    \n",
    "    def initialize_theta(self, x):\n",
    "        return [-1 for i in range(len(x[0]) + 1)]\n",
    "    \n",
    "    def scale(self, x):\n",
    "        x = np.array(x)\n",
    "        \n",
    "        x_normed = (x - x.mean(axis = 0))/(x.std(axis = 0))\n",
    "        \n",
    "        return x_normed\n",
    "    \n",
    "    def train(self, x, y, alpha, num_times, lamb):\n",
    "        new_x= self.scale(x)\n",
    "        #print(new_x)\n",
    "        theta = self.initialize_theta(new_x)\n",
    "        print(theta)\n",
    "        prev = self.reg_cost_function(new_x, theta, y, lamb)\n",
    "        while num_times > 0:\n",
    "            if num_times % 100 == 0:\n",
    "                print('Cost Function Value: ', self.reg_cost_function(new_x, theta, y, lamb))\n",
    "                print('Gradient: ', self.reg_gradient(x, y, theta, lamb))\n",
    "            theta = self.update_theta(theta, alpha, new_x, y, lamb)\n",
    "            curr = self.reg_cost_function(new_x, theta, y, lamb)\n",
    "            \n",
    "            prev = curr\n",
    "            num_times -= 1\n",
    "            \n",
    "        print(theta)\n",
    "        \n",
    "        self.theta = theta\n",
    "    #def regularized_train(self, x, y, alpha, num_times, lamb):\n",
    "    \n",
    "    \n",
    "    def test(self, x):\n",
    "        new_x = self.scale(x)\n",
    "        for x_vector in np.array(x):\n",
    "            x_vector = np.append(x_vector, 1)\n",
    "        return np.matrix([np.dot(self.theta, np.matrix(np.append(x_vector,1)) for x_vector in x]) \n",
    "                    \n",
    "b = LogisticRegression()\n",
    "data = pd.read_csv('Test/ex2data1.txt')\n",
    "dat = data.as_matrix().T\n",
    "y = dat[-1]\n",
    "x = dat[:-1].T\n",
    "print(x)\n",
    "print(y)\n",
    "b.train(x, y, 1, 1000, 0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
